\section*{2.1}

\noindent
We were told the following about how each class was generated:

\begin{itemize}
\item For each class we generate 10 centroids each. One class' centroid is 
generated using a bivariate Gaussian distribution $N((1, 0)^{T}, I)$ and the 
other is generated using another bivariate Gaussian distribution of 
$N((0, 1)^{T}, I)$.
\item An equal number of each class is generated by randomly selecting one of 
the 10 centroids uniformly, say $m_{k}$, and then generating a sample using a 
bivariate Gaussian distribution of $N(m_{k}, I / 5)$.
\end{itemize}

\noindent
If we take the randomly sampled centroids as given, we can find the most likely 
class that any point sampled in $\mathbb{R}^{2}$ would belong to. For any 
point, say $(x_{0}, y_{0})$, the centroid that is most likely to have generated 
the point is the centroid $k$ where 
$f(x_{0}, y_{0} | \mu = m_{k}, \sigma^{2} = I / 5)$ is maximized, where $f$ is 
the bivariate Gaussian density function. We then check which class that $m_{k}$ 
belongs to and classify that point as that class. To graphically display the 
Bayes' rate, we would select a fine mesh-point of points in $\mathbb{R}^{2}$ 
and compute and classify each mesh-point according to the above logic. at points 
where two centroids of different classes are equally both the most likely is 
where we will draw a boundary representing the Bayes' rate.

\vspace{5mm}
\noindent
Alternatively, because all of samples are generated from distributions with the 
same variance, it is sufficient to check which centroid is closest to the 
sample and then classify based on whichever class that centroid belongs to. 
Note that we cannot do this when variance is different for each distribution 
because distributions with higher variance are more likely to generate 
observations further away from their means as compared to lower variance 
distributions.